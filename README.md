Polling errors and fat tails
================

To me it always felt like â€œfat tailedâ€ errors was just another buzzword
as if throwing a student-t distribution with *Î½*â€„=â€„7 would magically
solve your problem of polling errors that put too little probability on
errors that are large. So here a test with some data.

To estimate polling errors I use the generic model

*y*<sub>*i*</sub>â€„âˆ¼â€„Binomial(logit<sup>â€…âˆ’â€…1</sup>(*n*<sub>*i*</sub>,â€†*Î±*<sub>*s*\[*i*\],â€†*t*\[*i*\]</sub>â€…+â€…*Î¾*<sub>*s*\[*i*\],â€†*t*\[*i*\]</sub>))

for state-polls three weeks prior to the Presidential election. *i*
indexes polls and *y* refers to the count of respondents indicating a
Democratic vote intention and *n* the number of respondents indicating
the intention to vote for either major party.
*Î±*<sub>*s*\[*i*\],â€†*t*\[*i*\]</sub> is the election result on the logit
scale for state *s* and election *t* for poll *i*. This is the
vectorized notation from Gelman and Hill (2006). *Î¾* is the polling
error, i.e.Â the difference between the election outcome and the poll
estimate. Now why do this rather than take the average of pre-election
poll polling errors. Well, sampling variation and we all generally love
propagating uncertainty.

Anyway, the question is where does *Î¾* come from. The candidates are
either the student-t distribution with some *Î½* and *Ïƒ* or the normal
distribution with some *Ïƒ*. Letâ€™s fix *Ïƒ*â€„=â€„0.1, i.e.Â encoding the
belief that 68% of the time the polling error falls within â€…Â±â€…14
percentage points. Overly wide maybe but then again there are the
Hawaiiâ€™s of this world so letâ€™s leave it like that. Then we can use
Stacking (i.e.Â a fancy Bayesian Model Averaging approach that works
through the predictive distribution) to compare multiple models
specifically those with

*Î¾*â€„âˆ¼â€„*t*<sub>student</sub>(*Î½*,â€†0,â€†0.1)

and those with

*Î¾*â€„âˆ¼â€„ğ’©(0,â€†0.1)

We can vary *Î½* where bigger means less wide tails. For comparison, in
blue *Î½*â€„=â€„2 and in red the normal.

![](README_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->

The fitted model in Stan then looks like this:

``` {c++}
data {
  int N;
  int S; // State
  int T; // Year
  int x[N];
  int y[N];
  int n[N];
  vector[N] outcome;
  int corr_x[S * T];
  real nu;
}
transformed data {
  vector[N] logit_outcome;
  logit_outcome = logit(outcome);
}
parameters {
  vector[S * T] xi_student_t;
}
model {
  xi_student_t ~ student_t(nu,0, 0.1);
  y ~ binomial_logit(n, logit_outcome + xi_student_t[x]);
}
generated quantities {
  vector[N] log_lik;
  for (ii in 1:N){
    log_lik[ii] = binomial_logit_lpmf(y[ii] | n[ii], logit_outcome[ii] + xi_student_t[x[ii]]);
  }
}
```

When this is run for varying values of *Î½*, we see that BMA suggests
that a fat tailed distribution provides a better fit to the data.

![](README_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->
